{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook calculates the impacts for each food item and each country that can potentially produce each food item specific to a country and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files from other python scripts\n",
    "data_dir = os.path.join('..','nb1','Input')\n",
    "data_trade = os.path.join('..','nb1','Trade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input required to run this notebook\n",
    "- location = country (as a cntry_rev key)\n",
    "- month = month (as a mnths key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run the notebook: \n",
    "#### The last function (calc_impacts) automatically incorporates all other functions in this notebook, therefore it is the only one necessary to run. The code: df = calc_impacts(location,month) will generate a dataframe with the food items, the nutrient content, and total food item impacts relevant to a specific country and month."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Relevant Columns and Description of Dataframe Content:\n",
    "Food Name : This is the name of the food item.\n",
    "totalGHG_all : These are the total impacts (all life cycle stages) for the food item depending on which country it is produced in (including transport to consumption country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Name</th>\n",
       "      <th>totalGHG_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almonds, flaked and ground</td>\n",
       "      <td>[(US, 0.0018018629108170147), (BF, 0.003356155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almonds, toasted</td>\n",
       "      <td>[(US, 0.0018018629108170147), (BF, 0.003356155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apples, eating, raw, flesh and skin, weighed w...</td>\n",
       "      <td>[(CL, 0.00035235256470952665), (CN, 0.00111999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apricots, raw, flesh and skin, weighed with st...</td>\n",
       "      <td>[(IT, 0.000549503882966546), (FR, 0.0005856304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apricots, raw, flesh and skin, weighed with st...</td>\n",
       "      <td>[(IT, 0.0014281962280577219), (FR, 0.000873965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>octopus, raw</td>\n",
       "      <td>[(CN, 0.0031703095058696505), (MA, 0.002774130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>squid, dried</td>\n",
       "      <td>[(KR, 0.0029866008907745516), (JP, 0.002987393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>squid, raw</td>\n",
       "      <td>[(KR, 0.003057083702021527), (JP, 0.0030578763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>sardines, flesh only, grilled</td>\n",
       "      <td>[(SN, 0.0028482180125111367), (VE, 0.002952952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>sardines, flesh only, raw</td>\n",
       "      <td>[(SN, 0.0026861354544874057), (VE, 0.002790870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Food Name  \\\n",
       "0                           almonds, flaked and ground   \n",
       "1                                     almonds, toasted   \n",
       "2    apples, eating, raw, flesh and skin, weighed w...   \n",
       "3    apricots, raw, flesh and skin, weighed with st...   \n",
       "4    apricots, raw, flesh and skin, weighed with st...   \n",
       "..                                                 ...   \n",
       "544                                       octopus, raw   \n",
       "545                                       squid, dried   \n",
       "546                                         squid, raw   \n",
       "547                      sardines, flesh only, grilled   \n",
       "548                          sardines, flesh only, raw   \n",
       "\n",
       "                                          totalGHG_all  \n",
       "0    [(US, 0.0018018629108170147), (BF, 0.003356155...  \n",
       "1    [(US, 0.0018018629108170147), (BF, 0.003356155...  \n",
       "2    [(CL, 0.00035235256470952665), (CN, 0.00111999...  \n",
       "3    [(IT, 0.000549503882966546), (FR, 0.0005856304...  \n",
       "4    [(IT, 0.0014281962280577219), (FR, 0.000873965...  \n",
       "..                                                 ...  \n",
       "544  [(CN, 0.0031703095058696505), (MA, 0.002774130...  \n",
       "545  [(KR, 0.0029866008907745516), (JP, 0.002987393...  \n",
       "546  [(KR, 0.003057083702021527), (JP, 0.0030578763...  \n",
       "547  [(SN, 0.0028482180125111367), (VE, 0.002952952...  \n",
       "548  [(SN, 0.0026861354544874057), (VE, 0.002790870...  \n",
       "\n",
       "[549 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfnew[['Food Name','totalGHG_all']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Food Code',\n",
       " 'Food Name',\n",
       " 'Description',\n",
       " 'Previous',\n",
       " 'Main data references',\n",
       " 'Footnote',\n",
       " 'Edible proportion',\n",
       " 'Specific gravity',\n",
       " 'Total solids',\n",
       " 'Nitrogen conversion factor ',\n",
       " 'Glycerol conversion factor',\n",
       " 'Water (g)',\n",
       " 'Total nitrogen (g)',\n",
       " 'Protein (g)',\n",
       " 'Fat (g)',\n",
       " 'Carbohydrate (g)',\n",
       " 'Energy (kcal) (kcal)',\n",
       " 'Energy (kJ) (kJ)',\n",
       " 'Starch (g)',\n",
       " 'Oligosaccharide (g)',\n",
       " 'Total sugars (g)',\n",
       " 'Glucose (g)',\n",
       " 'Galactose (g)',\n",
       " 'Fructose (g)',\n",
       " 'Sucrose (g)',\n",
       " 'Maltose (g)',\n",
       " 'Lactose (g)',\n",
       " 'Alcohol (g)',\n",
       " 'NSP (g)',\n",
       " 'AOAC fibre (g)',\n",
       " 'Satd FA /100g FA (g)',\n",
       " 'Satd FA /100g fd (g)',\n",
       " 'n-6 poly /100g FA (g)',\n",
       " 'n-6 poly /100g food (g)',\n",
       " 'n-3 poly /100g FA (g)',\n",
       " 'n-3 poly /100g food (g)',\n",
       " 'cis-Mono FA /100g FA (g)',\n",
       " 'cis-Mono FA /100g Food (g)',\n",
       " 'Mono FA/ 100g FA (g)',\n",
       " 'Mono FA /100g food (g)',\n",
       " 'cis-Polyu FA /100g FA (g)',\n",
       " 'cis-Poly FA /100g Food (g)',\n",
       " 'Poly FA /100g FA (g)',\n",
       " 'Poly FA /100g food (g)',\n",
       " 'Sat FA excl Br /100g FA (g)',\n",
       " 'Sat FA excl Br /100g food (g)',\n",
       " 'Branched chain FA /100g FA (g)',\n",
       " 'Branched chain FA /100g food (g)',\n",
       " 'Trans FAs /100g FA (g)',\n",
       " 'Trans FAs /100g food (g)',\n",
       " 'Cholesterol (mg)',\n",
       " 'Sodium (mg)',\n",
       " 'Potassium (mg)',\n",
       " 'Calcium (mg)',\n",
       " 'Magnesium (mg)',\n",
       " 'Phosphorus (mg)',\n",
       " 'Iron (mg)',\n",
       " 'Copper (mg)',\n",
       " 'Zinc (mg)',\n",
       " 'Chloride (mg)',\n",
       " 'Manganese (mg)',\n",
       " 'Selenium (µg)',\n",
       " 'Iodine (µg)',\n",
       " 'Retinol (µg)',\n",
       " 'Carotene (µg)',\n",
       " 'Retinol Equivalent (µg)',\n",
       " 'Vitamin D (µg)',\n",
       " 'Vitamin E (mg)',\n",
       " 'Vitamin K1 (µg)',\n",
       " 'Thiamin (mg)',\n",
       " 'Riboflavin (mg)',\n",
       " 'Niacin (mg)',\n",
       " 'Tryptophan/60 (mg)',\n",
       " 'Niacin equivalent (mg)',\n",
       " 'Vitamin B6 (mg)',\n",
       " 'Vitamin B12 (µg)',\n",
       " 'Folate (µg)',\n",
       " 'Pantothenate (mg)',\n",
       " 'Biotin (µg)',\n",
       " 'Vitamin C (mg)',\n",
       " 'All-trans-retinol (µg)',\n",
       " '13-cis-retinol (µg)',\n",
       " 'Dehydroretinol (µg)',\n",
       " 'Retinaldehyde (µg)',\n",
       " 'Alpha-carotene (µg)',\n",
       " 'Beta-carotene (µg)',\n",
       " 'Cryptoxanthins (µg)',\n",
       " 'Lutein (µg)',\n",
       " 'Lycopene (µg)',\n",
       " '25-hydroxy vitamin D3 (µg)',\n",
       " 'Cholecalciferol (µg)',\n",
       " '5-mehtyl folate (µg)',\n",
       " 'Alpha-tocopherol (mg)',\n",
       " 'Beta-tocopherol (mg)',\n",
       " 'Delta-tocopherol (mg)',\n",
       " 'Gamma-tocopherol (mg)',\n",
       " 'Alpha-tocotrienol (mg)',\n",
       " 'Gamma-tocotrienol (mg)',\n",
       " 'C4:0 /100g FA (g)',\n",
       " 'C6:0 /100g FA (g)',\n",
       " 'C8:0 /100g FA (g)',\n",
       " 'C10:0 /100g FA (g)',\n",
       " 'C11:0 ex Br /100g FA (g)',\n",
       " 'C12:0 /100g FA (g)',\n",
       " 'C12:0 ex Br /100g FA (g)',\n",
       " 'C13:0 /100g FA (g)',\n",
       " 'C13:0 ex Br /100g FA (g)',\n",
       " 'C14:0 /100g FA (g)',\n",
       " 'C14:0 ex Br /100g FA (g)',\n",
       " 'C15:0 /100g FA (g)',\n",
       " 'C15:0 ex Br /100g FA (g)',\n",
       " 'C16:0 /100g FA (g)',\n",
       " 'C16:0 ex Br /100g FA (g)',\n",
       " 'C17:0 /100g FA (g)',\n",
       " 'C17:0 ex Br /100g FA (g)',\n",
       " 'C18:0 /100g FA (g)',\n",
       " 'C18:0 ex Br /100g FA (g)',\n",
       " 'C19:0 /100g FA (g)',\n",
       " 'C20:0 /100g FA (g)',\n",
       " 'C20:0 ex Br /100g FA (g)',\n",
       " 'C22:0 /100g FA (g)',\n",
       " 'C22:0 ex Br /100g FA (g)',\n",
       " 'C24:0 /100g FA (g)',\n",
       " 'C24:0 ex Br /100g FA (g)',\n",
       " 'C25:0 ex Br /100g FA (g)',\n",
       " 'C4:0 /100g food (g)',\n",
       " 'C6:0 /100g food (g)',\n",
       " 'C8:0 /100g food (g)',\n",
       " 'C10:0 /100g food (g)',\n",
       " 'C11:0 ex Br /100g food (g)',\n",
       " 'C12:0 /100g food (g)',\n",
       " 'C12:0 ex Br /100g food (g)',\n",
       " 'C13:0 /100g food (g)',\n",
       " 'C13:0 ex Br /100g food (g)',\n",
       " 'C14:0 /100g food (g)',\n",
       " 'C14:0 ex Br /100g food (g)',\n",
       " 'C15:0 /100g food (g)',\n",
       " 'C15:0 ex Br /100g food (g)',\n",
       " 'C16:0 /100g food (g)',\n",
       " 'C16:0 ex Br /100g food (g)',\n",
       " 'C17:0 /100g food (g)',\n",
       " 'C17:0 ex Br /100g food (g)',\n",
       " 'C18:0 /100g food (g)',\n",
       " 'C18:0 ex Br /100g food (g)',\n",
       " 'C19:0 /100g food (g)',\n",
       " 'C20:0 /100g food (g)',\n",
       " 'C20:0 ex Br /100g food (g)',\n",
       " 'C22:0 /100g food (g)',\n",
       " 'C22:0 ex Br /100g food (g)',\n",
       " 'C24:0 /100g food (g)',\n",
       " 'C24:0 ex Br /100g food (g)',\n",
       " 'C25:0 ex Br /100g food (g)',\n",
       " 'C10:1 /100g FA (g)',\n",
       " 'cis C10:1 /100g FA (g)',\n",
       " 'C12:1 /100g FA (g)',\n",
       " 'cis C12:1 /100g FA (g)',\n",
       " 'C14:1 /100g FA (g)',\n",
       " 'cis C14:1 /100g FA (g)',\n",
       " 'C15:1 /100g FA (g)',\n",
       " 'cis C15:1 /100g FA (g)',\n",
       " 'C16:1 /100g FA (g)',\n",
       " 'cis C16:1 /100g FA (g)',\n",
       " 'C17:1 /100g FA (g)',\n",
       " 'cis C17:1 /100g FA (g)',\n",
       " 'C18:1 /100g FA (g)',\n",
       " 'cis C18:1 /100g FA (g)',\n",
       " 'cis/trans C18:1n-9 /100g FA (g)',\n",
       " 'cis/trans C18:1n-7 /100g FA (g)',\n",
       " 'C20:1 /100g FA (g)',\n",
       " 'cis C20:1 /100g FA (g)',\n",
       " 'C22:1 /100g FA (g)',\n",
       " 'cis C22:1 /100g FA (g)',\n",
       " 'cis/trans C22:1n-11 /100g FA (g)',\n",
       " 'cis/trans C22:1n-9 /100g FA (g)',\n",
       " 'C24:1 /100g FA (g)',\n",
       " 'cis C24:1 /100g FA (g)',\n",
       " 'trans monounsaturated /100g FA (g)',\n",
       " 'C10:1 /100g food (g)',\n",
       " 'cis C10:1 /100g food (g)',\n",
       " 'C12:1 /100g food (g)',\n",
       " 'cis C12:1 /100g food (g)',\n",
       " 'C14:1 /100g food (g)',\n",
       " 'cis C14:1 /100g food (g)',\n",
       " 'C15:1 /100g food (g)',\n",
       " 'cis C15:1 /100g food (g)',\n",
       " 'C16:1 /100g food (g)',\n",
       " 'cis C16:1 /100g food (g)',\n",
       " 'C17:1 /100g food (g)',\n",
       " 'cis C17:1 /100g food (g)',\n",
       " 'C18:1 /100g food (g)',\n",
       " 'cis C18:1 /100g food (g)',\n",
       " 'cis/trans C18:1n-9 /100g food (g)',\n",
       " 'cis/trans C18:1n-7 /100g food (g)',\n",
       " 'C20:1 /100g food (g)',\n",
       " 'cis C20:1 /100g food (g)',\n",
       " 'C22:1 /100g food (g)',\n",
       " 'cis C22:1 /100g food (g)',\n",
       " 'cis/trans C22:1n-11 /100g food (g)',\n",
       " 'cis/trans C22:1n-9 /100g food (g)',\n",
       " 'C24:1 /100g food (g)',\n",
       " 'cis C24:1 /100g food (g)',\n",
       " 'trans monounsaturated /100g food (g)',\n",
       " 'C16:2 /100g FA (g)',\n",
       " 'cis C16:2 /100g FA (g)',\n",
       " 'cis C16:3 /100g FA (g)',\n",
       " 'C16:4 /100g FA (g)',\n",
       " 'cis C16:4 /100g FA (g)',\n",
       " 'unknown C16 poly /100g FA (g)',\n",
       " 'C18:2 /100g FA (g)',\n",
       " 'cis n-6 C18:2 /100g FA (g)',\n",
       " 'C18:3 /100g FA (g)',\n",
       " 'cis n-3 C18:3 /100g FA (g)',\n",
       " 'cis n-6 C18:3 /100g FA (g)',\n",
       " 'C18:4 /100g FA (g)',\n",
       " 'cis n-3 C18:4 /100g FA (g)',\n",
       " 'unknown C18 poly /100g FA (g)',\n",
       " 'C20:2 /100g FA (g)',\n",
       " 'cis n-6 C20:2 /100g FA (g)',\n",
       " 'C20:3 /100g FA (g)',\n",
       " 'cis n-6 C20:3 /100g FA (g)',\n",
       " 'C20:4 /100g FA (g)',\n",
       " 'cis n-6 C20:4 /100g FA (g)',\n",
       " 'C20:5 /100g FA (g)',\n",
       " 'cis n-3 C20:5 /100g FA (g)',\n",
       " 'unknown C20 poly /100 FA (g)',\n",
       " 'C21:5 /100g FA (g)',\n",
       " 'cis n-3 C21:5 /100g FA (g)',\n",
       " 'C22:2 /100g FA (g)',\n",
       " 'cis n-6 C22:2 /100g FA (g)',\n",
       " 'cis n-6 C22:3 /100g FA (g)',\n",
       " 'C22:4 /100g FA (g)',\n",
       " 'cis n-6 C22:4 /100g FA (g)',\n",
       " 'C22:5 /100g FA (g)',\n",
       " 'cis n-3 C22:5 /100g FA (g)',\n",
       " 'C22:6 /100g FA (g)',\n",
       " 'cis n-3 C22:6 /100g FA (g)',\n",
       " 'unknown C22 poly /100g FA (g)',\n",
       " 'trans poly /100g FA (g)',\n",
       " 'C16:2 /100g food (g)',\n",
       " 'cis C16:2 /100g food (g)',\n",
       " 'C16:3 /100g food (g)',\n",
       " 'C16:4 /100g food (g)',\n",
       " 'cis C16:4 /100g food (g)',\n",
       " 'unknown C16 poly /100g food (g)',\n",
       " 'C18:2 /100g food (g)',\n",
       " 'cis n-6 C18:2 /100g food (g)',\n",
       " 'C18:3 /100g food (g)',\n",
       " 'cis n-3 C18:3 /100g food (g)',\n",
       " 'cis n-6 C18:3 /100g food (g)',\n",
       " 'C18:4 /100g food (g)',\n",
       " 'cis n-3 C18:4 /100g food (g)',\n",
       " 'unknown C18 poly /100g food (g)',\n",
       " 'C20:2 /100g food (g)',\n",
       " 'cis n-6 C20:2 /100g food (g)',\n",
       " 'C20:3 /100g food (g)',\n",
       " 'cis n-6 C20:3 /100g food (g)',\n",
       " 'C20:4 /100g food (g)',\n",
       " 'cis n-6 C20:4 /100g food (g)',\n",
       " 'C20:5 /100g food (g)',\n",
       " 'cis n-3 C20:5 /100g food (g)',\n",
       " 'unknown C20 poly /100g food (g)',\n",
       " 'C21:5 /100g food (g)',\n",
       " 'cis n-3 C21:5 /100g food (g)',\n",
       " 'C22:2 /100g food (g)',\n",
       " 'cis n-6 C22:2 /100g food (g)',\n",
       " 'cis n-6 C22:3 /100g food (g)',\n",
       " 'C22:4 /100g food (g)',\n",
       " 'cis n-6 C22:4 /100g food (g)',\n",
       " 'C22:5 /100g food (g)',\n",
       " 'cis n-3 C22:5 /100g food (g)',\n",
       " 'C22:6 /100g food (g)',\n",
       " 'cis n-3 C22:6 /100g food (g)',\n",
       " 'unknown C22 poly /100g food (g)',\n",
       " 'trans poly /100g food (g)',\n",
       " 'Total Phytosterols (mg)',\n",
       " 'Other Cholesterol and Phytosterols (mg)',\n",
       " 'Phytosterol (mg)',\n",
       " 'Beta-sitosterol (mg)',\n",
       " 'Brassicasterol (mg)',\n",
       " 'Campesterol (mg)',\n",
       " 'Delta-5-avenasterol (mg)',\n",
       " 'Delta-7-avenasterol (mg)',\n",
       " 'Delta-7-stigmastenol (mg)',\n",
       " 'Stigmasterol (mg)',\n",
       " 'Citric acid (g)',\n",
       " 'Malic acid (g)',\n",
       " 'Group',\n",
       " 'CF_search',\n",
       " 'product name',\n",
       " 'root *',\n",
       " 'conversion factor',\n",
       " '_merge',\n",
       " 'BW_search1',\n",
       " 'Omega3_DHA_EPA',\n",
       " 'Omega3_all',\n",
       " 'Omega3_AHA',\n",
       " 'Trans FA_kcal',\n",
       " 'PUFA_kcal_db_3_6',\n",
       " 'PUFA_kcal_db_6only',\n",
       " 'PUFA_kcal_db_3only',\n",
       " 'PUFA_kcal_POLY_DB',\n",
       " 'inventory_global',\n",
       " 'kgCO2per1000g',\n",
       " 'kgCO2per1g',\n",
       " 'Inventory0',\n",
       " 'Inventory1',\n",
       " 'Inventory2',\n",
       " 'Inventory3',\n",
       " 'Inventory4',\n",
       " 'Inventory5',\n",
       " 'Inventory6',\n",
       " 'Inventory7',\n",
       " 'Inventory8',\n",
       " 'Inventory9',\n",
       " 'Inventory10',\n",
       " 'Inventory11',\n",
       " 'Inventory12',\n",
       " 'Inventory13',\n",
       " 'Inventory14',\n",
       " 'Location0',\n",
       " 'Location1',\n",
       " 'Location2',\n",
       " 'Location3',\n",
       " 'Location4',\n",
       " 'Location5',\n",
       " 'Location6',\n",
       " 'Location7',\n",
       " 'Location8',\n",
       " 'Location9',\n",
       " 'Location10',\n",
       " 'Location11',\n",
       " 'Location12',\n",
       " 'Location13',\n",
       " 'Location14',\n",
       " 'Impacts0',\n",
       " 'Impacts1',\n",
       " 'Impacts2',\n",
       " 'Impacts3',\n",
       " 'Impacts4',\n",
       " 'Impacts5',\n",
       " 'Impacts6',\n",
       " 'Impacts7',\n",
       " 'Impacts8',\n",
       " 'Impacts9',\n",
       " 'Impacts10',\n",
       " 'Impacts11',\n",
       " 'Impacts12',\n",
       " 'Impacts13',\n",
       " 'Impacts14',\n",
       " 'countrylist',\n",
       " 'countryimpacts',\n",
       " 'regional_kgCO2_gram',\n",
       " 'Processing_kWh_gram_elec',\n",
       " 'Processing_kWh_gram_steam',\n",
       " 'regional_landbio_pergram',\n",
       " 'root',\n",
       " 'global_landbio_gram',\n",
       " 'seasonal_landbio',\n",
       " 'seasonal_kgCO2',\n",
       " 'percentimpacts_all',\n",
       " 'percentimpacts_eco',\n",
       " 'totalGHG_all',\n",
       " 'totalGHG_eco',\n",
       " 'bio_all',\n",
       " 'bio_eco',\n",
       " 'optimization_country_landbio_1_all',\n",
       " 'optimization_value_landbio_1_all',\n",
       " 'optimization_country_landbio_2_all',\n",
       " 'optimization_value_landbio_2_all',\n",
       " 'optimization_country_landbio_3_all',\n",
       " 'optimization_value_landbio_3_all',\n",
       " 'optimization_country_landbio_1_eco',\n",
       " 'optimization_value_landbio_1_eco',\n",
       " 'optimization_country_landbio_2_eco',\n",
       " 'optimization_value_landbio_2_eco',\n",
       " 'optimization_country_landbio_3_eco',\n",
       " 'optimization_value_landbio_3_eco',\n",
       " 'optimization_country_GHG_1_all',\n",
       " 'optimization_value_GHG_1_all',\n",
       " 'optimization_country_GHG_2_all',\n",
       " 'optimization_value_GHG_2_all',\n",
       " 'optimization_country_GHG_3_all',\n",
       " 'optimization_value_GHG_3_all',\n",
       " 'optimization_country_GHG_1_eco',\n",
       " 'optimization_value_GHG_1_eco',\n",
       " 'optimization_country_GHG_2_eco',\n",
       " 'optimization_value_GHG_2_eco',\n",
       " 'optimization_country_GHG_3_eco',\n",
       " 'optimization_value_GHG_3_eco',\n",
       " 'fishlocation',\n",
       " 'tradename',\n",
       " 'inseason',\n",
       " 'seasonal_kgCO2_updated',\n",
       " 'seasonal_landbio_updated',\n",
       " 'countriesthatproduceit_season_GHG',\n",
       " 'countriesthatproduceit_season_BIO',\n",
       " 'Food Item',\n",
       " 'home_cooked',\n",
       " 'transport',\n",
       " 'storage_frozen',\n",
       " 'storage_refrig',\n",
       " 'proc_elec',\n",
       " 'proc_heat',\n",
       " 'optimization_country_BIO_1_all',\n",
       " 'optimization_value_BIO_1_all',\n",
       " 'trade_impacts_GHG',\n",
       " 'trade_impacts_BIO',\n",
       " 'optimization_value_GHG_1_trade',\n",
       " 'optimization_country_GHG_1_trade',\n",
       " 'bio_GHGopt_value1',\n",
       " 'optimization_value_BIO_1_trade',\n",
       " 'optimization_country_BIO_1_trade',\n",
       " 'GHG_bioopt_value1',\n",
       " 'Food',\n",
       " 'Trade']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfnew.columns.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cntry_rev = np.load(os.path.join(data_dir,'trandict.npy'),allow_pickle='TRUE').item()\n",
    "mnths = {'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data to Build the Country and Month Specific Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transport Life Cycle Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrycodes = pd.read_excel(os.path.join(data_dir,'For7b.xlsx'))\n",
    "countrydict = dict(zip(countrycodes['name'],countrycodes['iso 3166_2']))\n",
    "clean_dict = {k: v for k, v in countrydict.items() if pd.Series(v).notna().all()}\n",
    "# need to replace some values in the country codes database to match with seasonality\n",
    "# keys are from seasonality database\n",
    "# values are from ecoinvent country list\n",
    "countrydict2 = {'Antigua and Barbuda':'Antigua & Barbuda','Bahamas':'British Virgin Is.',\n",
    "    'Bolivia, Plurinational State of':'Bolivia','Bosnia and Herzegovina':'Bosnia & Herzegovin', 'Bouvet Island' :'Bouvet I.',\n",
    "     'British Indian Ocean Territory':'British Indian Ocea','Brunei Darussalam':'Brunei','Cayman Islands':'Cayman Is.',\n",
    "      'Central African Republic':'Central African Rep','Christmas Island': 'Christmas I.', 'Cocos (Keeling) Islands':'Cocos Is.',\n",
    "    'Congo, Democratic Republic of the':'Congo, DRC','Cook Islands':'Cook Is.',\"Cote d'Ivoire\":\"Cote d'Ivory\",\n",
    "          'Falkland Islands (Malvinas)':'Falkland Is.','Faroe Islands':'Faroe Is.',\n",
    "    'French Southern Territories':'French Southern & A','Heard Island and McDonald Islands':'Heard I. & McDonald',\n",
    "     'Iran (Islamic Republic of)':'Iran',\"Korea, Democratic People's Republic of\":'North Korea',\n",
    "    'Korea, Republic of':'South Korea',\"Lao People's Democratic Republic\":'Laos',\n",
    "    'Macedonia, the Former Yugoslav Republic of':'Macedonia','Marshall Islands':'Marshall Is.',\n",
    "    'Micronesia, Federated States of':'Micronesia','Moldova, Republic of':'Moldova','Pitcairn':'Pitcairn Is.',\n",
    "    'Russian Federation':'Russia','Sao Tome and Principe':'Sao Tome & Principe',\n",
    "      'Solomon Islands':'Solomon Is.','South Georgia and the South Sandwich Islands':'South Georgia & the',\n",
    "    'Svalbard and Jan Mayen':'Svalbard','Saint Kitts and Nevis': 'St. Kitts & Nevis', 'Saint Lucia': 'St. Lucia',\n",
    " 'Saint Pierre and Miquelon': 'St. Pierre & Miquel', 'Saint Vincent and the Grenadines': 'St. Vincent & the G',\n",
    "      'Saint Helena':'St. Helena','Syrian Arab Republic':'Syria','Taiwan, Province of China':'Taiwan',\n",
    " 'Tanzania, United Republic Of':'Tanzania','Gambia':'The Gambia','Bahamas':'The Bahamas',\n",
    "    'Trinidad and Tobago':'Trinidad & Tobago','Turks and Caicos Islands':'Turks & Caicos Is.',\n",
    "  'United Arab Emirates': 'United Arab Emirate', 'Viet Nam': 'Vietnam', 'Virgin Islands, British': 'Virgin Is.',\n",
    "   'Wallis and Futuna':'Wallis & Futuna',  'United States Minor Outlying Islands': 'Virgin Islands, U.S.',           \n",
    "    'Palestinian Territory, Occupied':'West Bank'}\n",
    "revcountrydict2 = {y:x for x,y in countrydict2.items()}\n",
    "countrycodes['name'].replace(countrydict2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = pd.read_pickle(os.path.join(data_dir,'transport_new.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transdict = dict(zip(countrycodes['iso 3166_3'],countrycodes['shortcut']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFG': 'AF',\n",
       " nan: 'CN-ZJ',\n",
       " 'ALB': 'AL',\n",
       " 'DZA': 'DZ',\n",
       " 'ASM': 'AS',\n",
       " 'AND': 'AD',\n",
       " 'AGO': 'AO',\n",
       " 'AIA': 'AI',\n",
       " 'ATA': 'AQ',\n",
       " 'ATG': 'AG',\n",
       " 'ARG': 'AR',\n",
       " 'ARM': 'AM',\n",
       " 'ABW': 'AW',\n",
       " 'AUS': 'AU',\n",
       " 'AUT': 'AT',\n",
       " 'AZE': 'AZ',\n",
       " 'BHS': 'BS',\n",
       " 'BHR': 'BH',\n",
       " 'BGD': 'BD',\n",
       " 'BRB': 'BB',\n",
       " 'BLR': 'BY',\n",
       " 'BEL': 'BE',\n",
       " 'BLZ': 'BZ',\n",
       " 'BEN': 'BJ',\n",
       " 'BMU': 'BM',\n",
       " 'BTN': 'BT',\n",
       " 'BOL': 'BO',\n",
       " 'BIH': 'BA',\n",
       " 'BWA': 'BW',\n",
       " 'BVT': 'BV',\n",
       " 'BRA': 'BR',\n",
       " 'IOT': 'IO',\n",
       " 'BRN': 'BN',\n",
       " 'BGR': 'BG',\n",
       " 'BFA': 'BF',\n",
       " 'BDI': 'BI',\n",
       " 'KHM': 'KH',\n",
       " 'CMR': 'CM',\n",
       " 'CAN': 'CA',\n",
       " 'CPV': 'CV',\n",
       " 'CYM': 'KY',\n",
       " 'CAF': 'CF',\n",
       " 'TCD': 'TD',\n",
       " 'CHL': 'CL',\n",
       " 'CHN': 'CN',\n",
       " 'CXR': 'CX',\n",
       " 'CCK': 'CC',\n",
       " 'COL': 'CO',\n",
       " 'COM': 'KM',\n",
       " 'COG': 'CG',\n",
       " 'COD': 'CD',\n",
       " 'COK': 'CK',\n",
       " 'CRI': 'CR',\n",
       " 'CIV': 'CI',\n",
       " 'HRV': 'HR',\n",
       " 'CUB': 'CU',\n",
       " 'CUW': 'CW',\n",
       " 'CYP': 'CY',\n",
       " 'CZE': 'CZ',\n",
       " 'DNK': 'DK',\n",
       " 'DJI': 'DJ',\n",
       " 'DMA': 'DM',\n",
       " 'DOM': 'DO',\n",
       " 'ECU': 'EC',\n",
       " 'EGY': 'EG',\n",
       " 'SLV': 'SV',\n",
       " 'GNQ': 'GQ',\n",
       " 'ERI': 'ER',\n",
       " 'EST': 'EE',\n",
       " 'ETH': 'ET',\n",
       " 'FLK': 'FK',\n",
       " 'FRO': 'FO',\n",
       " 'FJI': 'FJ',\n",
       " 'FIN': 'FI',\n",
       " 'FRA': 'FR',\n",
       " 'GUF': 'GF',\n",
       " 'PYF': 'PF',\n",
       " 'ATF': 'TF',\n",
       " 'GAB': 'GA',\n",
       " 'GMB': 'GM',\n",
       " 'GEO': 'GE',\n",
       " 'DEU': 'DE',\n",
       " 'GHA': 'GH',\n",
       " 'GIB': 'GI',\n",
       " 'GRC': 'GR',\n",
       " 'GRL': 'GL',\n",
       " 'GRD': 'GD',\n",
       " 'GLP': 'GP',\n",
       " 'GUM': 'GU',\n",
       " 'GTM': 'GT',\n",
       " 'GGY': 'GG',\n",
       " 'GIN': 'GN',\n",
       " 'GNB': 'GW',\n",
       " 'GUY': 'GY',\n",
       " 'HTI': 'HT',\n",
       " 'HMD': 'HM',\n",
       " 'VAT': 'VA',\n",
       " 'HND': 'HN',\n",
       " 'HKG': 'HK',\n",
       " 'HUN': 'HU',\n",
       " 'ISL': 'IS',\n",
       " 'IND': 'IN',\n",
       " 'IDN': 'ID',\n",
       " 'IRN': 'IR',\n",
       " 'IRQ': 'IQ',\n",
       " 'IRL': 'IE',\n",
       " 'IMN': 'IM',\n",
       " 'ISR': 'IL',\n",
       " 'ITA': 'IT',\n",
       " 'JAM': 'JM',\n",
       " 'JPN': 'JP',\n",
       " 'JEY': 'JE',\n",
       " 'JOR': 'JO',\n",
       " 'KAZ': 'KZ',\n",
       " 'KEN': 'KE',\n",
       " 'KIR': 'KI',\n",
       " 'PRK': 'KP',\n",
       " 'KOR': 'KR',\n",
       " 'KWT': 'KW',\n",
       " 'KGZ': 'KG',\n",
       " 'LAO': 'LA',\n",
       " 'LVA': 'LV',\n",
       " 'LBN': 'LB',\n",
       " 'LSO': 'LS',\n",
       " 'LBR': 'LR',\n",
       " 'LBY': 'LY',\n",
       " 'LIE': 'LI',\n",
       " 'LTU': 'LT',\n",
       " 'LUX': 'LU',\n",
       " 'MAC': 'MO',\n",
       " 'MKD': 'MK',\n",
       " 'MDG': 'MG',\n",
       " 'MWI': 'MW',\n",
       " 'MYS': 'MY',\n",
       " 'MDV': 'MV',\n",
       " 'MLI': 'ML',\n",
       " 'MLT': 'MT',\n",
       " 'MHL': 'MH',\n",
       " 'MTQ': 'MQ',\n",
       " 'MRT': 'MR',\n",
       " 'MUS': 'MU',\n",
       " 'MYT': 'YT',\n",
       " 'MEX': 'MX',\n",
       " 'FSM': 'FM',\n",
       " 'MDA': 'MD',\n",
       " 'MCO': 'MC',\n",
       " 'MNG': 'MN',\n",
       " 'MNE': 'ME',\n",
       " 'MSR': 'MS',\n",
       " 'MAR': 'MA',\n",
       " 'MOZ': 'MZ',\n",
       " 'MMR': 'MM',\n",
       " 'NAM': nan,\n",
       " 'NRU': 'NR',\n",
       " 'NPL': 'NP',\n",
       " 'NLD': 'NL',\n",
       " 'NCL': 'NC',\n",
       " 'NZL': 'NZ',\n",
       " 'NIC': 'NI',\n",
       " 'NER': 'NE',\n",
       " 'NGA': 'NG',\n",
       " 'NIU': 'NU',\n",
       " 'NFK': 'NF',\n",
       " 'MNP': 'MP',\n",
       " 'NOR': 'NO',\n",
       " 'OMN': 'OM',\n",
       " 'PAK': 'PK',\n",
       " 'PLW': 'PW',\n",
       " 'PSE': 'PS',\n",
       " 'PAN': 'PA',\n",
       " 'PNG': 'PG',\n",
       " 'PRY': 'PY',\n",
       " 'PER': 'PE',\n",
       " 'PHL': 'PH',\n",
       " 'PCN': 'PN',\n",
       " 'POL': 'PL',\n",
       " 'PRT': 'PT',\n",
       " 'PRI': 'PR',\n",
       " 'QAT': 'QA',\n",
       " 'REU': 'RE',\n",
       " 'ROU': 'RO',\n",
       " 'RUS': 'RU',\n",
       " 'RWA': 'RW',\n",
       " 'BLM': 'BL',\n",
       " 'SHN': 'SH',\n",
       " 'KNA': 'KN',\n",
       " 'LCA': 'LC',\n",
       " 'MAF': 'MF',\n",
       " 'SPM': 'PM',\n",
       " 'VCT': 'VC',\n",
       " 'WSM': 'WS',\n",
       " 'SMR': 'SM',\n",
       " 'STP': 'ST',\n",
       " 'SAU': 'SA',\n",
       " 'SEN': 'SN',\n",
       " 'SRB': 'RS',\n",
       " 'SYC': 'SC',\n",
       " 'SLE': 'SL',\n",
       " 'SGP': 'SG',\n",
       " 'SXM': 'SX',\n",
       " 'SVK': 'SK',\n",
       " 'SVN': 'SI',\n",
       " 'SLB': 'SB',\n",
       " 'SOM': 'SO',\n",
       " 'ZAF': 'ZA',\n",
       " 'SGS': 'GS',\n",
       " 'SSD': 'SS',\n",
       " 'ESP': 'ES',\n",
       " 'LKA': 'LK',\n",
       " 'SDN': 'SD',\n",
       " 'SUR': 'SR',\n",
       " 'SJM': 'SJ',\n",
       " 'SWZ': 'SZ',\n",
       " 'SWE': 'SE',\n",
       " 'CHE': 'CH',\n",
       " 'SYR': 'SY',\n",
       " 'TWN': 'TW',\n",
       " 'TJK': 'TJ',\n",
       " 'TZA': 'TZ',\n",
       " 'THA': 'TH',\n",
       " 'TLS': 'TL',\n",
       " 'TGO': 'TG',\n",
       " 'TKL': 'TK',\n",
       " 'TON': 'TO',\n",
       " 'TTO': 'TT',\n",
       " 'TUN': 'TN',\n",
       " 'TUR': 'TR',\n",
       " 'TKM': 'TM',\n",
       " 'TCA': 'TC',\n",
       " 'TUV': 'TV',\n",
       " 'UGA': 'UG',\n",
       " 'UKR': 'UA',\n",
       " 'ARE': 'AE',\n",
       " 'GBR': 'GB',\n",
       " 'USA': 'US',\n",
       " 'UMI': 'UM',\n",
       " 'URY': 'UY',\n",
       " 'UZB': 'UZ',\n",
       " 'VUT': 'VU',\n",
       " 'VEN': 'VE',\n",
       " 'VNM': 'VN',\n",
       " 'VGB': 'VG',\n",
       " 'VIR': 'VI',\n",
       " 'WLF': 'WF',\n",
       " 'ESH': 'EH',\n",
       " 'YEM': 'YE',\n",
       " 'ZMB': 'ZM',\n",
       " 'ZWE': 'ZW'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport['country_eco_start']=transport['iso1'].map(transdict)\n",
    "transport['country_eco_end']=transport['iso2'].map(transdict)\n",
    "transport[['capitalport1','capitalport2','roaddistance']] = transport[['capitalport1','capitalport2','roaddistance']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor to go from straight line to road distance\n",
    "transport['roaddistance_km_new'] = transport['roaddistance_km_new']*1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of all possible countries included in the optimization\n",
    "trandict = pd.Series(transport['country1'].values,transport['country_eco_start'].values).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removecountries():\n",
    "    notfound = []\n",
    "    for k,v in trandict.items():\n",
    "        try:\n",
    "            direc = '/home/walkerch/Optimization_Tool/Output'\n",
    "            sub = pd.read_pickle(os.path.join(direc,k+'_trade.p'))\n",
    "            sub.to_pickle(os.path.join(data_trade,k+'_trade.p'))\n",
    "        except:\n",
    "            notfound.append((k,v))\n",
    "    return notfound\n",
    "#notfound = removecountries()\n",
    "#trandict = {k:v for k,v in trandict.items() if k not in [i[0] for i in notfound]}\n",
    "#np.save(os.path.join(data_dir,'trandict.npy'),trandict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transportimpactsfly(countries,location):    \n",
    "    editedtransport = transport[(transport['country_eco_start']==location)]\n",
    "    transportimpactslist = []\n",
    "    for i in countries:\n",
    "        sub = editedtransport[(editedtransport['country_eco_end']==i)]\n",
    "        try:  \n",
    "            dist_plane = (sub['flightdistance_km_new'].values[0]*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'dab659574eb0acdc7894d874752b3b90')\"]['GHG'].values[0]/1000000)         \n",
    "            if dist_plane == 0:\n",
    "                dist_road = (sub['roaddistance_km_new'].values[0]*\n",
    "                    other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'b9986f3a64dc89380350a4be59f85da1')\"]['GHG'].values[0]/1000000)\n",
    "                transportimpactslist.append(dist_road)       \n",
    "            else:\n",
    "                transportimpactslist.append(dist_plane)\n",
    "        except IndexError:\n",
    "            impacts = 0\n",
    "            transportimpactslist.append(impacts)\n",
    "    return transportimpactslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transportfrozen(countries,location):\n",
    "    editedtransport = transport[(transport['country_eco_start']==location)]\n",
    "    transportimpactslist = []\n",
    "    for i in countries:\n",
    "        sub = editedtransport[editedtransport['country_eco_end']==i]\n",
    "        try:\n",
    "            if sub['roaddistance_km_new'].values[0]==0:  \n",
    "                dist_ship = (sub['seadistance'].values[0]*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', '44821b59b3166727b65c7b2fc63daab1')\"]['GHG'].values[0]/1000000)\n",
    "                dist_road = ((sub['capitalport1'].values[0]+sub['capitalport2'].values[0])*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'd2f13d15af29946b73584e52978f4520')\"]['GHG'].values[0]/1000000)\n",
    "\n",
    "                impacts = dist_ship+dist_road\n",
    "                transportimpactslist.append(impacts)\n",
    "            else:\n",
    "                dist_road2 = (sub['roaddistance_km_new'].values[0]*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'd2f13d15af29946b73584e52978f4520')\"]['GHG'].values[0]/1000000)\n",
    "                #transportimpactslist.append((i,dist_road2,'else')) # this was to check\n",
    "                transportimpactslist.append(dist_road2)\n",
    "        except IndexError:\n",
    "                impacts = 0\n",
    "                transportimpactslist.append(impacts)\n",
    "    return transportimpactslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transportimpacts2(countries,location):    \n",
    "    editedtransport = transport[(transport['country_eco_start']==location)]\n",
    "    transportimpactslist = []\n",
    "    for i in countries:\n",
    "        sub = editedtransport[(editedtransport['country_eco_end']==i)]\n",
    "        try:\n",
    "            if sub['roaddistance_km_new'].values[0]==0:  \n",
    "                dist_ship = (sub['seadistance'].values[0]*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', '61441303ba5832f6f371d58ba9bfc7c0')\"]['GHG'].values[0]/1000000)\n",
    "                dist_road = ((sub['capitalport1'].values[0]+sub['capitalport2'].values[0])*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'b9986f3a64dc89380350a4be59f85da1')\"]['GHG'].values[0]/1000000)\n",
    "\n",
    "                impacts = dist_ship+dist_road\n",
    "                #transportimpactslist.append((i,impacts,'if')) # this was to check\n",
    "                transportimpactslist.append(impacts)\n",
    "            else:\n",
    "                dist_road2 = (sub['roaddistance_km_new'].values[0]*\n",
    "                         other_impacts[other_impacts['key']==\n",
    "                        \"('cutoff35', 'b9986f3a64dc89380350a4be59f85da1')\"]['GHG'].values[0]/1000000)\n",
    "                #transportimpactslist.append((i,dist_road2,'else')) # this was to check\n",
    "                transportimpactslist.append(dist_road2)\n",
    "        except IndexError:\n",
    "                impacts = 0\n",
    "                transportimpactslist.append(impacts)\n",
    "    return transportimpactslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality of Fresh Fruits and Vegetables\n",
    "- which countries grow which crops during which months for each fresh fruit and vegetable\n",
    "- this is only applicable to fresh fruits and vegetables. Any processed items (canned, frozen, or dried), items capable of longer term storage (grains, nuts, processed food items), or items not influenced by seasonality (fish, meats and meat/dairy products). Fish capture could be seasonal, but this was not included.\n",
    "- this was based on Pfister water demand schedule. **This work could be greatly improved by incorporating country specific fruit and vegetable seasonality rather than depending on the water demand schedule**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseasonality = pd.read_pickle(os.path.join(data_dir,'for7optseasonality.p'))\n",
    "newseasonality['crop'] = newseasonality['crop_jan']\n",
    "## add mushrooms to always be in season (can be grown year round)\n",
    "newseasonality.loc[newseasonality['crop']=='mushroom',:'CI_dec'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnths = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "mnths_change = ['mar','apr','may','jun','jul','aug','sep','oct','nov','dec','jan','feb'] # to shift by two months\n",
    "seasonality = pd.DataFrame()\n",
    "for i,j in zip(mnths,mnths_change):\n",
    "    sub = newseasonality.filter(regex=i)\n",
    "    sub.columns = [col.replace('_%s'%i,'_%s'%j)for col in sub.columns]\n",
    "    seasonality = pd.concat([seasonality,sub],axis=1)\n",
    "seasonality['crop'] = newseasonality['crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make these products avaiable year round due to storage but only in Switzerland because of trade restrictions\n",
    "listofcolumns = seasonality.filter(regex='CH').columns.tolist()\n",
    "mask = (seasonality['crop'].str.contains('carrot'))|(seasonality['crop'].str.contains('onion'))|\\\n",
    "        (seasonality['crop'].str.contains('^apple'))|(seasonality['crop'].str.contains('^potato')\n",
    "                                                     |(seasonality['crop'].str.contains('kiwi')))\n",
    "seasonality.at[mask,listofcolumns] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonalitydict = seasonality.set_index('crop').T.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonalavailability(location,month):\n",
    "    df = pd.read_pickle(os.path.join(data_dir,'for_7g_opt_prep.p'))\n",
    "\n",
    "    # find seasonal availability for all fresh fruits and vegetables and make a new column with the production impacts and locations\n",
    "    maskf_v = (df['Group'].isin(['DGC','DGR','FAT']))&(~df['Food Name'].str.contains('canned|frozen|pickled|dried'))\n",
    "    seasonalitydictmonth = {k1:{k2:v2 for k2,v2 in v1.items() if ((month in k2)&(v2==1)) } for k1,v1 in seasonalitydict.items()}\n",
    "    maskother = ~maskf_v\n",
    "    countryproddict = {k1:{k2:v2 for k2,v2 in v1.items() if (v2==1) } for k1,v1 in seasonalitydict.items()}\n",
    "    df['inseason'] = df[maskf_v]['root *'].map(seasonalitydictmonth) # the countries that produce it that month for fresh foods\n",
    "    df['inseason2'] = df[maskother]['root *'].map(countryproddict) # all countries that can produce it for processed foods\n",
    "    def countries(row1):\n",
    "        try:\n",
    "            c = list(set([i[0] for i in row1]))\n",
    "        except: \n",
    "            c = 'no global production'\n",
    "        return c\n",
    "     \n",
    "    df['inseason'] = df['inseason'].fillna(df['inseason2']) # combines inseason columns into a dictionary of all country sources\n",
    "                                                            # of that food item for that month. Does not include non-crop items.\n",
    "    df = df.drop('inseason2',1)\n",
    "    def breakapart(row1,row2):\n",
    "        # take the countries this product is produced in during this month, and find the overlapping regional impacts \n",
    "        try:\n",
    "            c= [i.split('_')[0] for i in row1]\n",
    "            newlist = list(set(c).intersection([i[0] for i in row2]))\n",
    "            newsubsea1 = list(set(c)-set(newlist))\n",
    "            for item in row2:\n",
    "                if item[0] in ['RoW','GLO']:\n",
    "                    generic = [(i,item[1]) for i in newsubsea1]\n",
    "                else: pass\n",
    "            b = [item for item in row2 if item[0] in newlist]+generic\n",
    "        except:\n",
    "            c='Not in season anywhere'\n",
    "            newlist = 'no overlap with regional production data'\n",
    "            b = 'Not in season anywhere'\n",
    "        return b\n",
    "    df['seasonal_kgCO2_updated'] = df.apply(lambda row:breakapart(row['inseason'],\\\n",
    "                                                                            row['regional_kgCO2_gram']),axis=1)\n",
    "    df['seasonal_landbio_updated'] = df.apply(lambda row:breakapart(row['inseason'],\\\n",
    "                                                                            row['regional_landbio_pergram']),axis=1)\n",
    "    df.loc[maskother,'seasonal_kgCO2_updated'] = np.where(df.loc[maskother,'seasonal_kgCO2_updated']=='Not in season anywhere',\n",
    "                                 df.loc[maskother,'seasonal_kgCO2'],df.loc[maskother,'seasonal_kgCO2_updated'] )\n",
    "    \n",
    "    df.loc[maskother,'seasonal_landbio_updated'] = np.where(df.loc[maskother,'seasonal_landbio_updated']=='Not in season anywhere',\n",
    "                    df.loc[maskother,'regional_landbio_pergram'],df.loc[maskother,'seasonal_landbio_updated'] )   \n",
    "    \n",
    "    df['countriesthatproduceit_season_GHG'] = df.apply(lambda row:countries(row['seasonal_kgCO2_updated']),axis=1) \n",
    "    df['countriesthatproduceit_season_BIO'] = df.apply(lambda row:countries(row['seasonal_landbio_updated']),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Home Cooking Life Cycle Stages\n",
    "####  electricity (regional) and steam impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_impacts = pd.read_excel(os.path.join(data_dir,'otherimpacts.xlsx'))\n",
    "other_impacts.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elecprocessingimpacts(countries,location,elec):\n",
    "\n",
    "    proc_elec_impacts_loc = []\n",
    "    if any(location not in s for s in countries):\n",
    "        for i in countries:\n",
    "            try:\n",
    "                prodelecimpacts = elec*other_impacts[(other_impacts['country']==i)&\n",
    "                    (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "                proc_elec_impacts_loc.append(prodelecimpacts)\n",
    "            except IndexError:\n",
    "                prodelecimpacts = elec*other_impacts[(other_impacts['country']=='RoW')&\n",
    "                    (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "                proc_elec_impacts_loc.append(prodelecimpacts)\n",
    "    else:\n",
    "        prodelecimpact=elec*other_impacts[(other_impacts['country']==location)&\n",
    "                                          (other_impacts['unit']=='kilowatt hour')]['GHG'].values[0]\n",
    "        proc_elec_impacts_loc.append(prodelecimpact)\n",
    "    proc_elec_impacts_loc = [0 if math.isnan(x) else x for x in proc_elec_impacts_loc]\n",
    "    return proc_elec_impacts_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamprocessingimpacts(countries,prodsteam):\n",
    "\n",
    "    prodsteamimpact = prodsteam*other_impacts[(other_impacts['name'].str.contains('steam',na=False))\n",
    "                             &(other_impacts['country']=='RoW')]['GHG'].values[0]/3.6\n",
    "    steamimpacts = [prodsteamimpact]*len(countries)\n",
    "    steamimpacts = [0 if math.isnan(x) else x for x in steamimpacts]\n",
    "    return steamimpacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homecookingbeans(countries,location):\n",
    "\n",
    "    cookingenergy = 0.0011625 \n",
    "    testimpact = other_impacts[(other_impacts['country']==location)&\\\n",
    "                                    (other_impacts['unit'].str.contains('kilowatt hour'))]['GHG'].values[0]\n",
    "    \n",
    "    driedbeans1 = cookingenergy*testimpact\n",
    "    driedbeans2 = [driedbeans1]*len(countries)\n",
    "    driedbeans = [0 if math.isnan(x) else x for x in driedbeans2]\n",
    "    return driedbeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homecookingvegetablesmeats(countries,location):\n",
    "    #Energy Use for Cooking and Other Stages in the Life Cycle of Food\n",
    "    mincooking = 0.000356481 # kWh/gram\n",
    "    maxcooking = 0.000939815 # kWh/gram\n",
    "    avgcooking = np.mean([mincooking,maxcooking])\n",
    "    impact = other_impacts[(other_impacts['country']==location)&\\\n",
    "                                    (other_impacts['unit'].str.contains('kilowatt hour'))]['GHG'].values[0]   \n",
    "    test1 = avgcooking*impact\n",
    "    test2 = [test1]*len(countries)\n",
    "    homecooked = [0 if math.isnan(x) else x for x in test2]  \n",
    "    return homecooked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Life Cycle Stage Impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storagelength = pd.read_excel(os.path.join(data_dir,'storage_information.xlsx'), sheet_name = 'freshfoodstoragetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storagedisplayenergy = pd.read_excel(os.path.join(data_dir,'storage_information.xlsx'), sheet_name = 'displaycaseenergyuse')\n",
    "processedfoodresidencetime = pd.read_excel(os.path.join(data_dir,'storage_information.xlsx'), sheet_name = 'processedfoodresidencetime')\n",
    "processedfoodresidencetime=processedfoodresidencetime.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longtermstorage = pd.read_excel(os.path.join(data_dir,'storage_information.xlsx'), sheet_name = 'refridgeratedstorage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storagefunccooled(countries,location,month):\n",
    "    length = len(countries)\n",
    "    meat_cheese_milk = []\n",
    "    for i in ['freshmeat','cheese','milk']:\n",
    "        hoursstored = (processedfoodresidencetime[processedfoodresidencetime['product']==i]['warehouse_h'].values[0]\n",
    "        +processedfoodresidencetime[processedfoodresidencetime['product']==i]['store_h'].values[0])\n",
    "        elec = np.mean(storagedisplayenergy[storagedisplayenergy['product'].str.contains(i)]['energy_kWh_kg_h'])/1000# change to per gram\n",
    "        total = hoursstored*elec # total impacts to store cooled food long term  \n",
    "        impacts = other_impacts[(other_impacts['country']==location)&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "        cooledstoragedisplay = []\n",
    "        try:\n",
    "            storageimpacts = total*impacts\n",
    "            cooledstoragedisplay.append(storageimpacts)\n",
    "        except IndexError:\n",
    "            storageimpacts = total*other_impacts[(other_impacts['country']=='RoW')&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "            cooledstoragedisplay.append(storageimpacts)\n",
    "        cooledstorage = cooledstoragedisplay*length\n",
    "        meat_cheese_milk.append(cooledstorage)\n",
    "\n",
    "    return meat_cheese_milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storagefuncfrozen(countries,location,month):\n",
    "\n",
    "    length = len(countries)\n",
    "    hoursstored = 10*30*24 # 10 months, 30 days per month, 24 hours per day\n",
    "    elec = np.mean(longtermstorage[longtermstorage['product'].str.contains('frozen')]['energyperkgfoodperhour_kWh'])/1000# change to per gram\n",
    "    total = hoursstored*elec # total impacts to store frozen food long term  \n",
    "    \n",
    "    hoursstoreddisplay = 120 #hrs\n",
    "    elecdisplay = np.mean(storagedisplayenergy[storagedisplayenergy['product'].str.contains('frozen')]['energy_kWh_kg_h'])/1000\n",
    "    totaldisplay = hoursstoreddisplay*elecdisplay\n",
    "    \n",
    "    \n",
    "    frozenstoragelong = []\n",
    "    frozenstoragedisplay = []\n",
    "    try:\n",
    "        storageimpacts = total*other_impacts[(other_impacts['country']==location)&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "        frozenstoragelong.append(storageimpacts)\n",
    "        storageimpacts2 = totaldisplay*other_impacts[(other_impacts['country']==location)&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]  \n",
    "        frozenstoragedisplay.append(storageimpacts2)    \n",
    "        \n",
    "    except IndexError:\n",
    "            storageimpacts = total*other_impacts[(other_impacts['country']=='RoW')&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "            frozenstoragelong.append(storageimpacts)\n",
    "            storageimpacts2 = totaldisplay*other_impacts[(other_impacts['country']=='RoW')&\n",
    "                        (other_impacts['name']=='market for electricity, medium voltage')]['GHG'].values[0]\n",
    "            frozenstoragedisplay.append(storageimpacts2)\n",
    "    frozenstoragelong = frozenstoragelong*length\n",
    "    frozenstoragedisplay = frozenstoragedisplay*length\n",
    "    totalstorage = np.array(frozenstoragedisplay)+np.array(frozenstoragelong)\n",
    "    totalstorage = totalstorage.tolist()\n",
    "    return totalstorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding life cycle stage impacts and their contribution to the total impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumimpacts(base,trans,elec,heat,sto_fro,sto_ref,home):\n",
    "    try:\n",
    "        add =   [(n,m+t+e+h+l+d+hc) for (n,m,t,e,h,l,d,hc) in zip(\n",
    "           [i[0] for i in base],[i[1] for i in base],[i for i in trans],[i for i in elec],\n",
    "            [i for i in heat],[i for i in sto_fro],[i for i in sto_ref],[i for i in home])]\n",
    "        return add\n",
    "    except:return 'Not in season'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentimpacts(base,trans,elec,heat,sto_fro,sto_ref,home):\n",
    "    try:\n",
    "        add = [((m+t+e+h+l+d+hc),('prod_%s'%n,round((m/(m+t+e+h+l+d+hc))*100)),\\\n",
    "             ('trans',round((t/(m+t+e+h+l+d+hc))*100)), ('elecprod',round((e/(m+t+e+h+l+d+hc))*100)),\n",
    "             ('steamprod',round((h/(m+t+e+h+l+d+hc))*100)),('homecooking',round((hc/(m+t+e+h+l+d+hc))*100)),\n",
    "             ('longfreez',round((l/(m+t+e+h+l+d+hc))*100)), ('display',round((d/(m+t+e+h+l+d+hc))*100)))    \n",
    "            for n,m,t,e,h,l,d,hc in zip([i[0] for i in base],[i[1] for i in base],[i for i in trans],[i for i in elec],\n",
    "            [i for i in heat],[i for i in sto_fro],[i for i in sto_ref],[i for i in home])]\n",
    "        return add\n",
    "    except:return 'Not in season'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtradedata(column1,column2,column3,column4,location):\n",
    "    try:\n",
    "        tr = column1 +[(location,0)]\n",
    "        newlist = list(set([i[0] for i in column2]).intersection([i[0] for i in tr]))\n",
    "        tr = [item for item in column2 if item[0] in newlist]\n",
    "        return tr\n",
    "    except: \n",
    "        tr = column2\n",
    "        return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimpcou(row1,row2):\n",
    "    try:return sorted([(j,i) for i,j in row1])[0][1]\n",
    "    except:\n",
    "        try:\n",
    "            return sorted([(j,i) for i,j in row2])[0][1]\n",
    "        except:return 0\n",
    "def minimp(row1,row2):\n",
    "    try:return sorted([(j,i) for i,j in row1])[0][0]\n",
    "    except:\n",
    "        try:return sorted([(j,i) for i,j in row2])[0][0]\n",
    "        except:return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getothervalue(column1,column2):\n",
    "    try:return [i[1] for i in column1 if column2 in i][0]\n",
    "    except: \n",
    "        try:return np.mean([i[1] for i in column1])\n",
    "        except: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biocalc(column1,column2,column3):\n",
    "    newlist1 = [i[0] for i in column1]\n",
    "    newlist2 = [i for i in column3 if i[0] in newlist1]\n",
    "    newlist3 = [i for i in newlist2 if not any(isinstance(n, float) and math.isnan(n) for n in i)]\n",
    "    return newlist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcolumn(row1,row2):\n",
    "    if row2 =='FAT':\n",
    "        keep = ['frozen', 'dessicated','canned']\n",
    "        name = [i for i in row1.split(', ')][:1]\n",
    "        other = [i for i in row1.split(', ') if any(i.startswith(s) for s in keep)]\n",
    "        final = ', '.join(name+other)\n",
    "        #name = [i for i in row1.replace(',','').split() if i in keep]#[0]\n",
    "        return final\n",
    "    \n",
    "    if row2 in ('DGR','DGC','DFR','DFC','DAR','DAC'):\n",
    "        keep = ['frozen', 'boiled in unsalted water','canned','baby','steamed','mature','pickled','fried','baked',\\\n",
    "                'cherry','red','white/mooli','acorn','butternut','spaghetti','green','bulbs','dried','sugar-snap'\\\n",
    "               ,'microwaved','flesh']\n",
    "        name = [i for i in row1.split(', ')][:1]\n",
    "        other = [i for i in row1.split(', ') if any(i.startswith(s) for s in keep)]\n",
    "        final = ', '.join(name+other)\n",
    "        return final        \n",
    "    if row2 in ('DBR','DBC'):\n",
    "        keep = ['frozen', 'boiled','canned','dried']\n",
    "        name = [i for i in row1.split(', ')][:2][::-1]\n",
    "        name = [name[0]+' '+name[1]]\n",
    "        other = [i for i in row1.split(', ') if any(i.startswith(s) for s in keep)]\n",
    "        final = ', '.join(name+other)\n",
    "        return final      \n",
    "    if row2 in ('BAE','BAH','BAK','BLS','BLM','BLH','BLF','BN','BJC','BNV','BAV'):\n",
    "        try:\n",
    "            \n",
    "            return ([i for i in row1.split(', ')][1]+' '+[i for i in row1.split(', ')][0]+' '+\\\n",
    "                   ', '.join([i for i in row1.split(', ')][2:]))\n",
    "        except IndexError:\n",
    "            try:\n",
    "                return ([i for i in row1.split(', ')][1]+' '+[i for i in row1.split(', ')][0])\n",
    "            except IndexError:\n",
    "                return ([i for i in row1.split(', ')][0])           \n",
    "    if row2 in('MI'):\n",
    "        return row1.replace('_avg','')\n",
    "   \n",
    "    else: \n",
    "        return row1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editforCH(df):\n",
    "    mask = (df['Food Name'].str.contains('carrot'))|(df['Food Name'].str.contains('onion'))|\\\n",
    "              (df['Food Name'].str.contains('^apple'))|(df['Food Name'].str.contains('^potato'))|\\\n",
    "                (df['Food Name'].str.contains('cheese'))|\\\n",
    "            ((df['Food Name'].str.contains('milk'))&(~df['Food Name'].str.contains('soy')))\n",
    "\n",
    "    for i in df[mask].index.tolist():\n",
    "        try:\n",
    "            df.at[i,'optimization_value_GHG_1_trade'] = [j[1] for j in df.loc[i,'trade_impacts_GHG'] if j[0]=='CH'][0]\n",
    "            df.at[i,'optimization_country_GHG_1_trade'] = [j[0] for j in df.loc[i,'trade_impacts_GHG'] if j[0]=='CH'][0]\n",
    "            df.at[i,'optimization_value_BIO_1_trade'] = [j[1] for j in df.loc[i,'trade_impacts_BIO'] if j[0]=='CH'][0]\n",
    "            df.at[i,'optimization_country_BIO_1_trade'] = [j[0] for j in df.loc[i,'trade_impacts_BIO'] if j[0]=='CH'][0]\n",
    "        except:\n",
    "            try:\n",
    "                df.at[i,'optimization_value_GHG_1_trade'] = min([(j[1],j[0]) for j in df.loc[i,'trade_impacts_GHG']])[0]\n",
    "                df.at[i,'optimization_country_GHG_1_trade'] = min([(j[1],j[0]) for j in df.loc[i,'trade_impacts_GHG']])[1]\n",
    "                df.at[i,'optimization_value_BIO_1_trade'] = min([(j[1],j[0]) for j in df.loc[i,'trade_impacts_BIO']])[0]\n",
    "                df.at[i,'optimization_country_BIO_1_trade'] = min([(j[1],j[0]) for j in df.loc[i,'trade_impacts_BIO']])[1]        \n",
    "            except:\n",
    "                df.at[i,'optimization_value_GHG_1_trade'] = 0\n",
    "                df.at[i,'optimization_country_GHG_1_trade'] = 0\n",
    "                df.at[i,'optimization_value_BIO_1_trade'] = 0\n",
    "                df.at[i,'optimization_country_BIO_1_trade'] = 0                \n",
    "           \n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function below uses all functions above to build the food item, nutrient, impact database that is pulled into the diet optimization tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_impacts(location,month):\n",
    "    \n",
    "##################### SET UP OPTIMIZATION PROBLEM ####################################################################    \n",
    "\n",
    "    # import nutrient database and edit fresh food item availability based on season/month\n",
    "    df = seasonalavailability(location,month)\n",
    "    df['Food Item'] = df.apply(lambda row:newcolumn(row['Food Name'],row['Group']),axis=1)\n",
    "    # new columns to add impacts\n",
    "    for i in ['home_cooked','transport','storage_frozen','storage_refrig','proc_elec','proc_heat','totalGHG_all',\n",
    "              'percentimpacts_all','optimization_country_GHG_1_all','optimization_value_GHG_1_all',\n",
    "                'optimization_country_BIO_1_all','optimization_value_BIO_1_all','trade_impacts_GHG','trade_impacts_BIO',\n",
    "                'optimization_value_GHG_1_trade','optimization_country_GHG_1_trade','bio_GHGopt_value1',\n",
    "              'optimization_value_BIO_1_trade','optimization_country_BIO_1_trade','GHG_bioopt_value1',\n",
    "               'trade_impacts_GHG','trade_impacts_BIO']:\n",
    "        df[i]=0\n",
    "        df[i]=df[i].astype(object)\n",
    "        \n",
    "    # home cooking masks and impacts\n",
    "    maskdriedbeans = (df['Food Name'].str.contains('dried'))&((df['Group'].str.startswith('DBR'))|\\\n",
    "        (df['Group'].str.startswith('DFR')))&(~df['Food Name'].str.contains('canned'))#maskdriedbeans\n",
    "    boiledathomebean =  (df['Food Name'].str.contains('beans|lentils'))&(df['Food Name'].str.contains('boiled'))#boiledathomebean\n",
    "    homecooking = np.logical_or(maskdriedbeans,boiledathomebean)\n",
    "    # masks for other cooked foods\n",
    "    cookedgrains = (df['Group'].str.startswith('AC'))|(df['Group'].str.startswith('DA'))|\\\n",
    "        (df['Group'].str.startswith('AA'))|(df['Group'].str.startswith('AD'))\n",
    "    cookedmeatandfish = ((df['Group'].str.startswith('M'))&(df['Group'].str.endswith('C')))|\\\n",
    "          ((df['Group'].str.startswith('J'))&(df['Group'].str.endswith('C')))\n",
    "    cookedstarch = df['Group']=='DAC';vegproducts = df['Group']=='VEG'; vegcooked =df['Group']=='DGC' # cookedveggies\n",
    "    cookedeggs = (df['Group'].str.startswith('CA'))\n",
    "    cookedall = pd.Series(np.any((vegproducts,vegcooked,cookedgrains,cookedeggs,cookedmeatandfish,cookedstarch),axis=0))\n",
    "    # cooking impacts\n",
    "    df.at[homecooking,'home_cooked'] = df[homecooking].apply(lambda row:homecookingbeans(\\\n",
    "                [i[0] for i in row['seasonal_kgCO2_updated']],location),axis=1) # add impacts for cooking beans\n",
    "    df.at[cookedall,'home_cooked'] = df[cookedall].apply(lambda row:homecookingvegetablesmeats(\\\n",
    "                [i[0] for i in row['seasonal_kgCO2_updated']],location),axis=1)  # add impacts for cooking everything else\n",
    "    df.at[~(homecooking|cookedall),'home_cooked'] = df[(~(homecooking|cookedall))]\\\n",
    "        .apply(lambda row:[0]*(len([i[0] for i in row['seasonal_kgCO2_updated']])),axis=1) # add 0 for things that don't need to be cooked\n",
    " \n",
    "    # transport impacts\n",
    "    meat = [1035,1058,1166,1501,1527,1540,1553,1562,1570,867,977] # roots for meat products\n",
    "    frozenalways = df['Food Name'].str.contains('frozen') # frozen food products\n",
    "    frozenfortransport = df['root *'].isin(meat)&(~df['Food Name'].str.contains('canned'))\n",
    "    frozen = np.logical_or(frozenalways,frozenfortransport)\n",
    "    cannedprocessed = df['Food Name'].str.contains('canned|pickled')\n",
    "    maskflown = (df['root *'].isin(['raspberry','blueberry','strawberry','lettuce','spinach',\n",
    "                    'papaya','asparagus','tropicalnes','mango'])& df['Food Name'].str.contains('raw')&\n",
    "                  ~df['Food Name'].str.contains('frozen|canned'))\n",
    "    remaining = ~pd.Series(np.any((cannedprocessed,frozen,maskflown),axis=0))\n",
    "    # calculate transport impacts zip1: masks, zip2:functions\n",
    "    for mask,function in zip([maskflown,frozen,cannedprocessed,remaining],\\\n",
    "                 [transportimpactsfly,transportfrozen,transportimpacts2,transportimpacts2]):\n",
    "        df.at[mask,'transport'] = df.loc[mask].apply(lambda row:\n",
    "                                function([i[0] for i in row['seasonal_kgCO2_updated']],location),axis=1)\n",
    "    df.at[cannedprocessed,'transport'] = df.loc[cannedprocessed].apply(lambda row:([i*2 for i in row['transport']]),axis=1)\n",
    "    \n",
    "    #storage impacts\n",
    "    meatstorage = df['root *'].isin(meat)&(~df['Food Name'].str.contains('frozen|canned|dried')) #refrigerated\n",
    "    milk = (df['root *']==882)&(~df['Food Name'].str.contains('cheese|butter')) #refrigerated\n",
    "    cheese = (df['root *']==882)&(df['Food Name'].str.contains('cheese|butter')) #refrigerated\n",
    "\n",
    "    df.at[frozenalways,'storage_frozen'] = df[frozenalways].apply(\n",
    "        lambda row:storagefuncfrozen([i[0] for i in row['seasonal_kgCO2_updated']],location,month),axis=1)\n",
    "    df.at[~frozenalways,'storage_frozen'] = df[~frozenalways].apply(\n",
    "        lambda row:[0]*(len([i[0] for i in row['seasonal_kgCO2_updated']])),axis=1)\n",
    "\n",
    "    for prod,num in zip([meatstorage,milk,cheese],[0,1,2]):\n",
    "        df.at[prod,'storage_refrig'] = df.loc[prod].apply(lambda row:storagefunccooled\\\n",
    "        ([i[0] for i in row['seasonal_kgCO2']],location,month)[num],axis=1)\n",
    "    df.at[~pd.Series(np.any((meatstorage,milk,cheese),axis=0)),'storage_refrig'] = \\\n",
    "            df.loc[~pd.Series(np.any((meatstorage,milk,cheese),axis=0))].\\\n",
    "            apply(lambda row:[0]*(len([i[0] for i in row['seasonal_kgCO2_updated']])),axis=1)\n",
    "    # processing impacts\n",
    "    mask1 = df['Processing_kWh_gram_elec'].notnull()\n",
    "    mask2 = df['Processing_kWh_gram_steam'].notnull()\n",
    "    df.at[mask1,'proc_elec'] = df[mask1].apply(lambda row:elecprocessingimpacts([i[0] for i in row['seasonal_kgCO2_updated']],\\\n",
    "                                location,row['Processing_kWh_gram_elec']),axis=1)\n",
    "    df.at[~mask1,'proc_elec'] = df[~mask1].apply(lambda row:[0]*len([i[0] for i in row['seasonal_kgCO2_updated']]),axis=1)\n",
    "    df.at[mask2,'proc_heat'] = (df[mask2]['Processing_kWh_gram_steam']*other_impacts[(other_impacts['name'].str.contains('steam',na=False))\n",
    "                    &(other_impacts['country']=='RoW')]['GHG'].values[0]/3.6)\n",
    "    df.at[mask2,'proc_heat']=df[mask2].apply(lambda row:[row['proc_heat']]*len([t[0] for t in row['seasonal_kgCO2_updated']]),axis=1)\n",
    "    df.at[~mask2,'proc_heat'] = df[~mask2].apply(lambda row:[0]*len([i[0] for i in row['seasonal_kgCO2_updated']]),axis=1)\n",
    "    \n",
    "    df['totalGHG_all'] = df.apply(lambda row:sumimpacts(row['seasonal_kgCO2_updated'],row['transport'],\n",
    "                    row['proc_elec'],row['proc_heat'],row['storage_frozen'],row['storage_refrig'],\n",
    "                   row['home_cooked']),axis=1)\n",
    "    df['percentimpacts_all'] = df.apply(lambda row:percentimpacts(row['seasonal_kgCO2_updated'],row['transport'],\n",
    "                    row['proc_elec'],row['proc_heat'],row['storage_frozen'],row['storage_refrig'],\n",
    "                   row['home_cooked']),axis=1)\n",
    "    \n",
    "    # find the minimum impact of all the countries that produce it\n",
    "   # df['optimization_country_GHG_1_all'] = df.apply(lambda row:minimpcou(row['totalGHG_all']),axis=1)\n",
    "    # df['optimization_value_GHG_1_all'] = df.apply(lambda row:minimp(row['totalGHG_all']),axis=1)\n",
    "    # df['optimization_country_BIO_1_all'] = df.apply(lambda row:minimpcou(row['trade_impacts_BIO'],row['seasonal_landbio_updated']),axis=1)\n",
    "    # df['optimization_value_BIO_1_all'] = df.apply(lambda row:minimp(row['trade_impacts_BIO'],row['seasonal_landbio_updated']),axis=1)\n",
    "    \n",
    "    # incorporate trade\n",
    "    trade = pd.read_pickle(os.path.join(data_trade,location+'_trade.p'))\n",
    "    newdf = pd.merge(df,trade,how = 'left', right_on = 'Food', left_on = 'tradename')\n",
    "    newdf['trade_impacts_GHG'] = newdf.apply(lambda row:addtradedata(row['Trade'],row['totalGHG_all'],row['Food Name'],\\\n",
    "                                                                row['Group'],location),axis=1)\n",
    "    mask = newdf['trade_impacts_GHG'].str.len()==0\n",
    "    newdf.at[mask,'trade_impacts_GHG']=newdf[mask]['totalGHG_all']\n",
    "    \n",
    "    # add lowest trade impacts values\n",
    "    newdf['seasonal_landbio_updated']=newdf.apply(lambda \\\n",
    "        row:[i for i in row['seasonal_landbio_updated'] if not any(isinstance(n, float) and math.isnan(n) for n in i)],axis=1)\n",
    "    \n",
    "    newdf['optimization_value_GHG_1_trade'] = newdf.apply(lambda row:minimp(row['trade_impacts_GHG'],row['totalGHG_all']),axis=1)\n",
    "    newdf['optimization_country_GHG_1_trade'] = newdf.apply(lambda row:minimpcou(row['trade_impacts_GHG'],row['totalGHG_all']),axis=1)\n",
    "    newdf['bio_GHGopt_value1'] = newdf.apply(lambda row:\\\n",
    "            getothervalue(row['seasonal_landbio_updated'],row['optimization_country_GHG_1_trade']),axis=1)\n",
    "    \n",
    "    newdf['trade_impacts_BIO'] = newdf.apply(lambda row:biocalc(row['trade_impacts_GHG'],\\\n",
    "           row['optimization_country_GHG_1_trade'],row['seasonal_landbio_updated']),axis=1)\n",
    "    \n",
    "    newdf['optimization_country_BIO_1_trade'] = newdf.apply(lambda row:minimpcou(row['trade_impacts_BIO'],\\\n",
    "                                                    row['seasonal_landbio_updated']),axis=1)\n",
    "    \n",
    "    newdf['optimization_value_BIO_1_trade'] = newdf.apply(lambda row:minimp(row['trade_impacts_BIO'],\\\n",
    "                                                    row['seasonal_landbio_updated']),axis=1)\n",
    "    newdf['GHG_bioopt_value1'] = newdf.apply(lambda row:\\\n",
    "            getothervalue(row['totalGHG_all'],row['optimization_country_BIO_1_trade']),axis=1)\n",
    "    \n",
    "    newdf = editforCH(newdf)\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run just this notebook to get the dataframe with impacts specific to a country and month:\n",
    "#df = calc_impacts(location,month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfnew = pd.read_pickle('testthis.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfnew.to_pickle('testthis.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new_environment]",
   "language": "python",
   "name": "conda-env-new_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
